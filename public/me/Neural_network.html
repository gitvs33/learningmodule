<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interactive Neural Network</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        .neuron {
            width: 80px;
            height: 80px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            position: relative;
            background-color: #2d3748; /* gray-800 */
            color: white;
            font-weight: 600;
            font-size: 1rem;
            border: 2px solid #4a5568; /* gray-600 */
            transition: all 0.3s ease;
        }
        .neuron-label {
            position: absolute;
            top: -25px;
            font-size: 0.8rem;
            font-weight: 500;
            color: #a0aec0; /* gray-400 */
            white-space: nowrap;
        }
        .neuron-value {
            font-size: 0.75rem;
            position: absolute;
            bottom: -20px;
            color: #cbd5e0; /* gray-300 */
            background-color: #1a202c;
            padding: 1px 4px;
            border-radius: 4px;
        }
        .connection {
            position: absolute;
            stroke: #4a5568; /* gray-600 */
            stroke-width: 2;
            transition: stroke 0.3s ease;
        }
        .weight-label {
            position: absolute;
            background-color: #1a202c; /* gray-900 */
            color: #e2e8f0; /* gray-200 */
            padding: 2px 6px;
            border-radius: 6px;
            font-size: 0.8rem;
            font-weight: 500;
            transform: translate(-50%, -50%);
            transition: all 0.3s ease;
            border: 1px solid #4a5568;
        }
        .highlight-line {
            stroke: #4299e1; /* blue-400 */
        }
        .highlight-neuron {
            border-color: #4299e1; /* blue-400 */
            transform: scale(1.1);
        }
        .highlight-weight {
            background-color: #4299e1; /* blue-400 */
            color: #1a202c; /* gray-900 */
            transform: translate(-50%, -50%) scale(1.1);
        }
        .explanation-card {
            background-color: #2d3748; /* gray-800 */
            border-radius: 0.5rem;
            padding: 1.5rem;
            border: 1px solid #4a5568; /* gray-700 */
        }
    </style>
</head>
<body class="bg-gray-900 text-gray-200">

    <div class="container mx-auto p-4 md:p-8">
        <header class="text-center mb-8">
            <h1 class="text-3xl md:text-4xl font-bold text-white">Interactive Neural Network Visualizer</h1>
            <p class="text-gray-400 mt-2">Simulating how a network learns to predict if a student will pass.</p>
        </header>

        <!-- Controls -->
        <div class="bg-gray-800 p-4 rounded-lg mb-8 max-w-2xl mx-auto flex flex-col md:flex-row items-center justify-center gap-6">
            <div class="w-full md:w-1/2">
                <label for="input-slider" class="block mb-2 font-medium text-gray-300">Hours Studied: <span id="slider-value" class="font-bold text-white">5</span></label>
                <input id="input-slider" type="range" min="0" max="10" step="0.1" value="5" class="w-full h-2 bg-gray-700 rounded-lg appearance-none cursor-pointer">
            </div>
            <button id="train-button" class="w-full md:w-auto bg-blue-600 hover:bg-blue-700 text-white font-bold py-2 px-6 rounded-lg transition-transform transform hover:scale-105">
                Train Network (1 Step)
            </button>
        </div>

        <!-- Visualization -->
        <div class="relative h-96 w-full max-w-4xl mx-auto mb-12" id="viz-container">
            <!-- SVG for connections -->
            <svg id="svg-connections" class="absolute top-0 left-0 w-full h-full overflow-visible z-0"></svg>

            <!-- Layers -->
            <div class="absolute w-full h-full flex justify-between items-center z-10">
                <!-- Input Layer -->
                <div id="input-layer" class="flex flex-col items-center">
                    <h3 class="font-semibold text-lg mb-4 text-gray-300">Input</h3>
                    <div id="input-neuron" class="neuron">
                        <span class="neuron-label">Hours</span>
                        <span id="input-neuron-value">5.0</span>
                    </div>
                </div>

                <!-- Hidden Layer -->
                <div id="hidden-layer" class="flex flex-col items-center">
                    <h3 class="font-semibold text-lg mb-4 text-gray-300">Hidden Layer</h3>
                    <div id="hidden-neuron" class="neuron">
                        <span class="neuron-label">Activation</span>
                        <span id="hidden-neuron-value">?</span>
                        <span class="neuron-value" id="hidden-calc-value"></span>
                    </div>
                </div>

                <!-- Output Layer -->
                <div id="output-layer" class="flex flex-col items-center">
                    <h3 class="font-semibold text-lg mb-4 text-gray-300">Output</h3>
                    <div id="output-neuron" class="neuron">
                         <span class="neuron-label">Pass Prob.</span>
                        <span id="output-neuron-value">?</span>
                        <span class="neuron-value" id="output-calc-value"></span>
                    </div>
                </div>
            </div>
        </div>

        <!-- Results -->
        <div class="max-w-2xl mx-auto grid grid-cols-1 md:grid-cols-3 gap-4 text-center mb-12">
            <div class="bg-gray-800 p-4 rounded-lg">
                <h4 class="font-semibold text-gray-400">Predicted Output</h4>
                <p id="prediction-value" class="text-2xl font-bold text-white">?</p>
            </div>
            <div class="bg-gray-800 p-4 rounded-lg">
                <h4 class="font-semibold text-gray-400">Actual Target</h4>
                <p id="target-value" class="text-2xl font-bold text-white">1.0</p>
            </div>
            <div class="bg-gray-800 p-4 rounded-lg">
                <h4 class="font-semibold text-gray-400">Loss (Error)</h4>
                <p id="loss-value" class="text-2xl font-bold text-red-400">?</p>
            </div>
        </div>

        <!-- Explanations -->
        <div class="max-w-4xl mx-auto space-y-6">
            <div class="grid grid-cols-1 md:grid-cols-2 gap-6">
                <div class="explanation-card">
                    <h3 class="text-xl font-bold mb-3 text-white">What a Neural Network Is: The Structure ‚öôÔ∏è</h3>
                    <p class="text-gray-300 mb-2">A network is built from simple, interconnected units organized in layers.</p>
                    <ul class="space-y-4 text-sm">
                        <li><strong class="text-blue-400">Neurons:</strong> The core units. A neuron takes in weighted inputs, adds a bias, and uses an 'activation function' (here, Sigmoid) to produce an output. In the visualization, each circle is a neuron.</li>
                        <li><strong class="text-blue-400">Layers:</strong> Neurons are grouped into layers. Data flows from the input layer, through the hidden layers (where most computation happens), to the output layer, which gives the final prediction.</li>
                        <li><strong class="text-blue-400">Weights & Biases:</strong> The learnable parameters. <strong class="text-white">Weights (w)</strong> on the connection lines determine how much influence one neuron has on the next. <strong class="text-white">Biases (b)</strong> are values inside a neuron that help it activate. The network learns by adjusting these values.</li>
                    </ul>
                </div>
                <div class="explanation-card">
                    <h3 class="text-xl font-bold mb-3 text-white">How a Neural Network Learns: The Engine üß†</h3>
                    <p class="text-gray-300 mb-2">The learning process, called 'training', is all about minimizing error.</p>
                    <ul class="space-y-4 text-sm">
                        <li><strong class="text-green-400">Forward Pass:</strong> When you change the input, data flows forward from left to right. This is the network making a prediction based on its current weights.</li>
                        <li><strong class="text-green-400">Loss Function:</strong> After a prediction, we use a loss function (here, Mean Squared Error) to calculate a single number representing the error. A lower loss is better.</li>
                        <li><strong class="text-green-400">Gradient Descent & Backpropagation:</strong> This is what happens when you click 'Train'. The network calculates the error's gradient (its slope) and works backward (Backpropagation) to see how much each weight and bias contributed to the error. It then 'descends' the gradient by nudging the weights and biases in the direction that reduces the error.</li>
                    </ul>
                </div>
            </div>
            <!-- New Explanation Card -->
            <div class="explanation-card">
                <h3 class="text-xl font-bold mb-3 text-white">Each Neuron Represents a Micro-Process üî¨</h3>
                <p class="text-gray-300 mb-2">You can think of each neuron as being responsible for a single, very specific micro-process or calculation.</p>
                <ul class="space-y-2 text-sm list-disc list-inside">
                    <li>The <strong class="text-white">Hidden Neuron's</strong> process is: "Based on the hours studied, what's an intermediate feature I can create?" It weighs the input, adds a bias, and decides how strongly to 'fire'.</li>
                    <li>The <strong class="text-white">Output Neuron's</strong> process is: "Given the feature from the hidden layer, what is the final probability of passing?"</li>
                </ul>
                <p class="text-gray-300 mt-4 text-sm">In larger networks (e.g., for image recognition), early neurons might process simple things like edges or colors. Later neurons combine these signals to recognize more complex patterns like eyes or faces. The network learns to orchestrate all these simple processes to solve the main problem.</p>
            </div>
        </div>
    </div>

    <script>
        document.addEventListener('DOMContentLoaded', () => {
            // --- DOM ELEMENTS ---
            const slider = document.getElementById('input-slider');
            const sliderValue = document.getElementById('slider-value');
            const trainButton = document.getElementById('train-button');
            const vizContainer = document.getElementById('viz-container');
            const svg = document.getElementById('svg-connections');
            
            const inputNeuronEl = document.getElementById('input-neuron');
            const hiddenNeuronEl = document.getElementById('hidden-neuron');
            const outputNeuronEl = document.getElementById('output-neuron');

            const inputNeuronValueEl = document.getElementById('input-neuron-value');
            const hiddenNeuronValueEl = document.getElementById('hidden-neuron-value');
            const outputNeuronValueEl = document.getElementById('output-neuron-value');
            
            const hiddenCalcValueEl = document.getElementById('hidden-calc-value');
            const outputCalcValueEl = document.getElementById('output-calc-value');

            const predictionValueEl = document.getElementById('prediction-value');
            const targetValueEl = document.getElementById('target-value');
            const lossValueEl = document.getElementById('loss-value');

            // --- NEURAL NETWORK PARAMETERS ---
            let nn = {
                w1: 0.2,   // Weight: Input -> Hidden
                b1: 0.1,   // Bias: Hidden
                w2: -0.3,  // Weight: Hidden -> Output
                b2: 0.4    // Bias: Output
            };
            
            let state = {
                input: 5.0,
                target: 1.0,
                learningRate: 0.1,
                hidden_pre_activation: 0,
                hidden_output: 0,
                output_pre_activation: 0,
                prediction: 0,
                loss: 0
            };

            // --- ACTIVATION FUNCTION ---
            const sigmoid = (x) => 1 / (1 + Math.exp(-x));
            const sigmoid_derivative = (x) => x * (1 - x);

            // --- UI & VISUALIZATION FUNCTIONS ---
            let w1Label, w2Label, line1, line2;

            function createConnections() {
                const inputPos = getElementCenter(inputNeuronEl, vizContainer);
                const hiddenPos = getElementCenter(hiddenNeuronEl, vizContainer);
                const outputPos = getElementCenter(outputNeuronEl, vizContainer);

                // Line 1: Input -> Hidden
                line1 = createLine(inputPos.x, inputPos.y, hiddenPos.x, hiddenPos.y);
                svg.appendChild(line1);
                w1Label = createWeightLabel(
                    (inputPos.x + hiddenPos.x) / 2,
                    (inputPos.y + hiddenPos.y) / 2,
                    `w1: ${nn.w1.toFixed(3)}`
                );
                vizContainer.appendChild(w1Label);

                // Line 2: Hidden -> Output
                line2 = createLine(hiddenPos.x, hiddenPos.y, outputPos.x, outputPos.y);
                svg.appendChild(line2);
                w2Label = createWeightLabel(
                    (hiddenPos.x + outputPos.x) / 2,
                    (outputPos.y + outputPos.y) / 2,
                    `w2: ${nn.w2.toFixed(3)}`
                );
                vizContainer.appendChild(w2Label);
            }
            
            function getElementCenter(el, container) {
                const rect = el.getBoundingClientRect();
                const containerRect = container.getBoundingClientRect();
                return {
                    x: rect.left - containerRect.left + rect.width / 2,
                    y: rect.top - containerRect.top + rect.height / 2
                };
            }

            function createLine(x1, y1, x2, y2) {
                const line = document.createElementNS('http://www.w3.org/2000/svg', 'line');
                line.setAttribute('x1', x1);
                line.setAttribute('y1', y1);
                line.setAttribute('x2', x2);
                line.setAttribute('y2', y2);
                line.classList.add('connection');
                return line;
            }

            function createWeightLabel(x, y, text) {
                const label = document.createElement('div');
                label.classList.add('weight-label');
                label.style.left = `${x}px`;
                label.style.top = `${y}px`;
                label.textContent = text;
                return label;
            }
            
            function updateUI() {
                // Update slider value text
                sliderValue.textContent = state.input.toFixed(1);
                
                // Update neuron values
                inputNeuronValueEl.textContent = state.input.toFixed(1);
                hiddenNeuronValueEl.textContent = state.hidden_output.toFixed(3);
                outputNeuronValueEl.textContent = state.prediction.toFixed(3);

                // Update calculation displays
                hiddenCalcValueEl.textContent = `Œ£ = ${state.hidden_pre_activation.toFixed(2)}`;
                outputCalcValueEl.textContent = `Œ£ = ${state.output_pre_activation.toFixed(2)}`;

                // Update weight labels
                w1Label.textContent = `w1: ${nn.w1.toFixed(3)}`;
                w2Label.textContent = `w2: ${nn.w2.toFixed(3)}`;
                
                // Update results
                predictionValueEl.textContent = state.prediction.toFixed(3);
                targetValueEl.textContent = state.target.toFixed(1);
                lossValueEl.textContent = state.loss.toFixed(4);
            }
            
            // --- CORE LOGIC ---
            function forwardPass() {
                // Input to Hidden
                state.hidden_pre_activation = (state.input * nn.w1) + nn.b1;
                state.hidden_output = sigmoid(state.hidden_pre_activation);

                // Hidden to Output
                state.output_pre_activation = (state.hidden_output * nn.w2) + nn.b2;
                state.prediction = sigmoid(state.output_pre_activation);
                
                calculateLoss();
                updateUI();
            }
            
            function calculateLoss() {
                const error = state.target - state.prediction;
                state.loss = Math.pow(error, 2); // Mean Squared Error
            }
            
            function train() {
                // --- Backpropagation ---
                
                // 1. Calculate gradient for the output layer
                const error = state.target - state.prediction;
                const d_prediction = error * 2; // Derivative of MSE
                const d_output_pre_activation = sigmoid_derivative(state.prediction);
                const output_delta = d_prediction * d_output_pre_activation;

                // 2. Calculate gradient for the hidden layer
                const error_hidden = output_delta * nn.w2;
                const d_hidden_pre_activation = sigmoid_derivative(state.hidden_output);
                const hidden_delta = error_hidden * d_hidden_pre_activation;

                // --- Gradient Descent (Update Weights & Biases) ---
                
                // Update output layer weights and bias
                nn.w2 += state.hidden_output * output_delta * state.learningRate;
                nn.b2 += output_delta * state.learningRate;
                
                // Update hidden layer weights and bias
                nn.w1 += state.input * hidden_delta * state.learningRate;
                nn.b1 += hidden_delta * state.learningRate;
                
                // Run forward pass again to show the updated prediction
                forwardPass();
                
                // Animate the training step
                animateTraining();
            }
            
            function animateTraining() {
                const allElements = [inputNeuronEl, hiddenNeuronEl, outputNeuronEl, w1Label, w2Label];
                const allLines = [line1, line2];
                
                // Flash highlight
                allElements.forEach(el => el.classList.add('highlight-neuron'));
                allLines.forEach(line => line.classList.add('highlight-line'));
                w1Label.classList.add('highlight-weight');
                w2Label.classList.add('highlight-weight');

                setTimeout(() => {
                    allElements.forEach(el => el.classList.remove('highlight-neuron'));
                    allLines.forEach(line => line.classList.remove('highlight-line'));
                    w1Label.classList.remove('highlight-weight');
                    w2Label.classList.remove('highlight-weight');
                }, 500);
            }

            // --- EVENT LISTENERS ---
            slider.addEventListener('input', (e) => {
                state.input = parseFloat(e.target.value);
                forwardPass();
            });
            
            trainButton.addEventListener('click', train);

            // --- INITIALIZATION ---
            createConnections();
            forwardPass();
        });
    </script>
</body>
</html>
